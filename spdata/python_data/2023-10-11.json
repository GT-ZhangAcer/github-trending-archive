[
  {
    "title": "",
    "url": "https://github.comundefined",
    "desc": "Dev tool that writes scalable apps from scratch while the developer oversees the implementation",
    "lang": "Python"
  },
  {
    "title": "",
    "url": "https://github.comundefined",
    "desc": "Build high-quality LLM apps - from prototyping, testing to production deployment and monitoring.",
    "lang": "Python"
  },
  {
    "title": "",
    "url": "https://github.comundefined",
    "desc": "Python - 100天从新手到大师",
    "lang": "Python"
  },
  {
    "title": "",
    "url": "https://github.comundefined",
    "desc": "GPT-powered chat for documentation, chat with your documents",
    "lang": "Python"
  },
  {
    "title": "",
    "url": "https://github.comundefined",
    "desc": "Visual Instruction Tuning: Large Language-and-Vision Assistant built towards multimodal GPT-4 level capabilities.",
    "lang": "Python"
  },
  {
    "title": "",
    "url": "https://github.comundefined",
    "desc": "",
    "lang": "Python"
  },
  {
    "title": "",
    "url": "https://github.comundefined",
    "desc": "为ChatGPT/GLM提供实用化交互界面，特别优化论文阅读/润色/写作体验，模块化设计，支持自定义快捷按钮&函数插件，支持Python和C++等项目剖析&自译解功能，PDF/LaTex论文翻译&总结功能，支持并行问询多种LLM模型，支持chatglm2等本地模型。兼容文心一言, moss, llama2, rwkv, claude2, 通义千问, 书生, 讯飞星火等。",
    "lang": "Python"
  },
  {
    "title": "",
    "url": "https://github.comundefined",
    "desc": "Langchain-Chatchat（原Langchain-ChatGLM）基于 Langchain 与 ChatGLM 等语言模型的本地知识库问答 | Langchain-Chatchat (formerly langchain-ChatGLM), local knowledge based LLM (like ChatGLM) QA app with langchain",
    "lang": "Python"
  },
  {
    "title": "",
    "url": "https://github.comundefined",
    "desc": "Stable Diffusion web UI",
    "lang": "Python"
  },
  {
    "title": "",
    "url": "https://github.comundefined",
    "desc": "ChatGLM-6B: An Open Bilingual Dialogue Language Model | 开源双语对话语言模型",
    "lang": "Python"
  },
  {
    "title": "",
    "url": "https://github.comundefined",
    "desc": "The official gpt4free repository | various collection of powerful language models",
    "lang": "Python"
  },
  {
    "title": "",
    "url": "https://github.comundefined",
    "desc": "潘多拉，一个让你呼吸顺畅的ChatGPT。Pandora, a ChatGPT client that lets you breathe freely.",
    "lang": "Python"
  },
  {
    "title": "",
    "url": "https://github.comundefined",
    "desc": "Code and documents of LongLoRA and LongAlpaca",
    "lang": "Python"
  },
  {
    "title": "",
    "url": "https://github.comundefined",
    "desc": "Image Polygonal Annotation with Python (polygon, rectangle, circle, line, point and image-level flag annotation).",
    "lang": "Python"
  },
  {
    "title": "",
    "url": "https://github.comundefined",
    "desc": "Langchain + Docker + Neo4j",
    "lang": "Python"
  },
  {
    "title": "",
    "url": "https://github.comundefined",
    "desc": "The official Python library for the OpenAI API",
    "lang": "Python"
  },
  {
    "title": "",
    "url": "https://github.comundefined",
    "desc": "The official repo of Qwen (通义千问) chat & pretrained large language model proposed by Alibaba Cloud.",
    "lang": "Python"
  },
  {
    "title": "",
    "url": "https://github.comundefined",
    "desc": "A series of large language models developed by Baichuan Intelligent Technology",
    "lang": "Python"
  },
  {
    "title": "",
    "url": "https://github.comundefined",
    "desc": "DeepSpeed is a deep learning optimization library that makes distributed training and inference easy, efficient, and effective.",
    "lang": "Python"
  },
  {
    "title": "",
    "url": "https://github.comundefined",
    "desc": "⚡ Building applications with LLMs through composability ⚡",
    "lang": "Python"
  },
  {
    "title": "",
    "url": "https://github.comundefined",
    "desc": "Next generation face swapper and enhancer",
    "lang": "Python"
  },
  {
    "title": "",
    "url": "https://github.comundefined",
    "desc": "ToRA is a series of Tool-integrated Reasoning LLM Agents designed to solve challenging mathematical reasoning problems by interacting with tools.",
    "lang": "Python"
  },
  {
    "title": "",
    "url": "https://github.comundefined",
    "desc": "Example models using DeepSpeed",
    "lang": "Python"
  },
  {
    "title": "",
    "url": "https://github.comundefined",
    "desc": "Hackable implementation of state-of-the-art open-source LLMs based on nanoGPT. Supports flash attention, 4-bit and 8-bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed.",
    "lang": "Python"
  },
  {
    "title": "",
    "url": "https://github.comundefined",
    "desc": "Finetune llama2-70b and codellama on MacBook Air without quantization",
    "lang": "Python"
  }
]